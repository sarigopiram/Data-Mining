install.packages("xlsx")
library(xlsx)
write.xlsx(output, "mydata.xlsx")
#implement page rank using R
library("igraph")
pageGraph<-read.graph("web-Google.txt")
output<-page.rank(pageGraph,damping = 0.85)
install.packages("rjava")
install.packages("xlsx")
library(xlsx)
write.xlsx(output, "mydata.xlsx")
#implement page rank using R
library("igraph")
pageGraph<-read.graph("web-Google.txt")
output<-page.rank(pageGraph,damping = 0.85)
install.packages("rJava")
install.packages("xlsx")
library(xlsx)
write.xlsx(output, "mydata.xlsx")
#implement page rank using R
library("igraph")
pageGraph<-read.graph("web-Google.txt")
#output<-page.rank(pageGraph,damping = 0.85)
capture.output(page.rank(pageGraph,damping = 0.85),
file = "foo.txt")
library("igraph")
pageGraph<-read.graph("web-Google.txt")
#output<-page.rank(pageGraph,damping = 0.85)
options(max.print=1000000)
capture.output(page.rank(pageGraph,damping = 0.85),
file = "foo.txt")
#implement page rank using R
library("igraph")
pageGraph<-read.graph("web-Google.txt")
#output<-page.rank(pageGraph,damping = 0.85)
options(max.print=1000000)
capture.output(page.rank(pageGraph,damping = 0.2),
file = "foo.txt")
require(XML)
imdburl<="http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdburl)
install.packages(XML)
imdburl<="http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdburl)
library(XML)
imdburl<="http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdburl)
install.package("XML")
imdburl<="http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdbTables)
install.packages("XML")
library(XML)
imdburl<="http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdbTables)
library(XML)
imdburl<-"http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbTables<-readHTML(imdburl)
print(imdbTables)
imdburl<-"http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbdoc<-htmlParse(imdburl)
imdbTables<-readHTML(imdbdoc)
print(imdbTables)
imdburl<-"http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbdoc<-htmlParse(imdburl)
imdbTables<-readHTMLtable(imdbdoc)
print(imdbTables)
imdburl<-"http://www.imdb.com/search/title?at=0&count=50&languages=en%7C1&sort=year"
imdbdoc<-htmlParse(imdburl)
imdbTables<-readHTMLTable(imdbdoc)
print(imdbTables)
print(length(imdbTables))
print(imdbTables[1])
print(imdbdoc.xmlName())
print(class(imdbdoc))
print(root(imdbdoc))
print(xmlName(imdbdoc))
print(imdbTables[1])
library(xlsx)
write.xlsx(imdbTables, "mydata.xlsx")
require(rJava)
library(xlsx)
write.xlsx(imdbTables, "mydata.xlsx")
install.packages("rJava")
library(xlsx)
write.xlsx(imdbTables, "mydata.xlsx")
library(rJava)
library(xlsx)
write.xlsx(imdbTables, "mydata.xlsx")
write.table(imdbTables[1], "c:/mydata.txt", sep="\t")
write.table(imdbTables[1], "mydata.txt", sep="\t")
getwd()
library(xlsx)
library(xlsx)
path<-"E:\\Spring 2015\\saritha"
filenames <- list.files(path, pattern="*.xml", full.names=TRUE)
outputFile<-file("outputfile.txt",open="w")
for(file1 in filenames){
inputFile <- file(file1, "r")
linn=readLines(inputFile)
for(i in 1:length(linn)){
line<<-linn[i]
textPattern<-regexpr("<text>",line)
while(textPattern!=-1){
print("testing")
}
}
inputFile.close()
}
print(line)
path<-"E:\\Spring 2015\\saritha"
filenames <- list.files(path, pattern="*.xml", full.names=TRUE)
outputFile<-file("outputfile.txt",open="w")
for(file1 in filenames){
inputFile <- file(file1, "r")
linn=readLines(inputFile)
for(i in 1:length(linn)){
line1<<-linn[i]
textPattern<-regexpr("<text>",line)
while(textPattern!=-1){
print("testing")
}
}
inputFile.close()
}
print(line1)
path<-"E:\\Spring 2015\\saritha"
filenames <- list.files(path, pattern="*.xml", full.names=TRUE)
outputFile<-file("outputfile.txt",open="w")
for(file1 in filenames){
inputFile <- file(file1, "r")
linn=readLines(inputFile)
for(i in 1:length(linn)){
line1<<-linn[i]
textPattern<-regexpr("<text>",line)
while(textPattern!=-1){
print(line1)
}
}
inputFile.close()
}
path<-"E:\\Spring 2015\\saritha"
filenames <- list.files(path, pattern="*.xml", full.names=TRUE)
outputFile<-file("outputfile.txt",open="w")
for(file1 in filenames){
inputFile <- file(file1, "r")
linn=readLines(inputFile)
for(i in 1:length(linn)){
line1<<-linn[i]
textPattern<-regexpr("<text>",line)
while(textPattern!=-1){
print(line1)
}
}
inputFile.close()
}
print(line1)
path<-"E:\\Spring 2015\\saritha"
filenames <- list.files(path, pattern="*.xml", full.names=TRUE)
outputFile<-file("outputfile.txt",open="w")
for(file1 in filenames){
inputFile <- file(file1, "r")
linn=readLines(inputFile)
print(length(linn))
for(i in 1:length(linn)){
line1<<-linn[i]
textPattern<-regexpr("<text>",line)
while(textPattern!=-1){
print(line1)
}
}
inputFile.close()
}
getwd();
sample = c("You're awesome and I love you",
"I hate and hate and hate. So angry. Die!",
"Impressed and amazed: you are peerless in your
achievement of unparalleled mediocrity.")
result = score.sentiment(sample, pos.words, neg.words)
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
head(pos.words)
result = score.sentiment(sample, pos.words, neg.words)
result
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = toUpper(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result = score.sentiment(sample, pos.words, neg.words)
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = toUpper(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = toupper(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = toupper(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
head(pos.words)
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
sample="We checked this place out this past Monday for their wing night. We have heard that their wings are great and decided it was finally time to check it out. Their wings are whole wings and crispy, which is a nice change of pace. I got their wet Cajun sauce and garlic butter wings. The Cajun did not have a bold enough flavor for me and their sauce is too thin. The sauce was also thin for the garlic butter, but that is more expected. They were better than average, but I don't like seeing all the sauce resting at the bottom of the boat. I would definitely come try this place out again to sample some of the other items on the menu, but this will probably not become a regular stop for wings anytime soon."
result = score.sentiment(sample, pos.words, neg.words)
result
print(pos.matches)
pos.matches
getwd();
setwd("E:\\Spring 2015\\Visual Analytics\\Project\\Sentiment")
pos.words = scan('positive.txt',what='character')
neg.words = scan('negative.txt',what='character')
head(pos.words)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list
# or a vector as an "l" for us
# we want a simple array of scores back, so we use
# "l" + "a" + "ply" = "laply":
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
print(pos.matches)
print(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
result = score.sentiment(sample, pos.words, neg.words)
result
